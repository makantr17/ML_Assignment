#!/usr/bin/env python
# coding: utf-8

# In[414]:


import numpy as np
import pandas as pd


# In[415]:


df=pd.read_csv('Arrest_Data_from_2010_to_Present.csv')


# In[416]:


df.shape


# In[417]:


df.columns


# In[418]:


df.info()


# In[419]:


# drop all empty rows
df=df.dropna(how='all')


# In[420]:


df['Arrest Date']= df['Arrest Date'].fillna(df['Arrest Date'].min)
df['Area Name']= df['Area Name'].fillna(df['Area Name'].min)
df['Reporting District']= df['Reporting District'].fillna(df['Reporting District'].min)
df['Charge Group Description']= df['Charge Group Description'].dropna()
df['Time']= df['Time'].interpolate()
df = df.dropna()
df['Charge Group Description'].isnull().sum()


# In[421]:


df.isnull().sum()


# In[422]:


# select row based on method
# rgx = r''
# df_drop = df.loc[df['Report ID'].str.contains(rgx, na=False, regex=True, case=False)]
# df = df[~df_drop]
# df.drop(df[df['Age'] < 25].index, inplace = True) 
# drop method

# df.drop(df[df['Report ID'].str.contains(rgx, na=False, regex=True, case=False)].index, inplace = True) 
# df.drop(df[df['Report ID'].isin(['  "status" : 500','  "error" : true','  "message" : "Internal error"', '}'])].index, inplace = True) 


# In[423]:


df['Report ID'] = df['Report ID'].astype(str).astype(int)


# In[424]:


df.info()


# In[425]:


# convert date
df['Arrest Date'] = pd.to_datetime(df['Arrest Date'])
# df['Arrest Date'] = df['Arrest Date'].dt.strftime('%m.%d.%Y')


# In[426]:


# let fill the nan in string columns to ''
# df['Charge Description'].fillna('', inplace=True)
# df['Cross Street'].fillna('', inplace=True)
# df['Charge Group Description'].fillna('', inplace=True)
# df['Cross Street'].fillna('', inplace=True)
# df['Time'].fillna(0.0, inplace=True)


# In[427]:


df.columns


# In[428]:


# Let start answering question


# In[429]:


# Question 1: How many booking of arrestees were made in 2018


# In[430]:


Arrestes_in_2018 = df.loc[df['Arrest Date'].dt.year == 2018]
print("Number of Arresstes in 2018 is:", Arrestes_in_2018.shape[0])


# In[431]:


Arrestes_in_2018['Area Name'].unique()


# In[432]:


#Question 2: HOw many bookings of arrestees were made in the area with most 2018
# method2- Arrestes_in_2018.groupby('Area Name')['Report ID'].count().reset_index().sort_values('Report ID',ascending=False).head(10)
highest_Arrestees = Arrestes_in_2018.groupby('Area Name')['Report ID'].nunique()
print("Highest 2018 Arrestes in Central Area: ", max(highest_Arrestees))


# In[433]:


# Question 3: find average age of arrestees for each per each charge group
Arrestes_in_2018.groupby('Charge Group Description')['Age'].mean().reset_index().sort_values('Age',ascending=False).drop(index=[19,17])


# In[434]:


#Question 3- Method2 
# averages = []
# for i in Arrestes_in_2018['Charge Group Description'].unique():
#     if i == 'Non-Criminal Detention' or i == 'Pre-Delinquency':
#         pass
#     else:
#         selected_One = Arrestes_in_2018['Age'].loc[Arrestes_in_2018['Charge Group Description'] == i]
#         averages.append({i: selected_One.loc[selected_One.notnull()].mean()})

# averages
    


# In[435]:


# Question 4 What is the 95% quantile of the age of the arrestee in 2018? 
# Only consider the following charge groups for your analysis
columns = ['Vehicle Theft', 'Robbery', 'Burglary', 'Receive Stolen Property']
Quantile_Age = Arrestes_in_2018['Age'].loc[Arrestes_in_2018['Charge Group Description'].isin(columns)].quantile(.95)
print("Quantile of Age :", Quantile_Age)


# In[ ]:





# In[436]:


# Q5. Felony arrest incidents have been dropping over the years. Using a trend line (linear estimation) for the data 
# from 2010 and 2018 (inclusive), what is the projected number of felony 
# arrests in 2019? Round to the nearest integer. Note, the data set includes arrests for misdemeanor, felonies, etc


# In[437]:


df['Charge'].str.contains('felony').sum()


# In[440]:


# murder, rape, burglary, kidnapping and arson
df['year'] = df['Arrest Date'].dt.year
data_2010to2018=df[(df['year'] >=2010) & (df['year'] <=2018) ]


# In[441]:


i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Larceny')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Other Assaults')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Receive Stolen Property')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Driving Under Influence')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Prostitution/Allied')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Moving Traffic Violations')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Liquor Laws')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Drunkeness')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Disturbing the Peace')].index
data_2010to2018.drop(i,inplace =True)
i = data_2010to2018[(data_2010to2018['Charge Group Description'] == 'Gambling')].index
data_2010to2018.drop(i,inplace =True)


# In[442]:


felony_dataset=data_2010to2018.copy()
felony_dataset=felony_dataset[['year','Charge Group Description']]
felony_dataset


# In[443]:


import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from pandas.plotting import autocorrelation_plot
from pandas import DataFrame
from statsmodels.tsa.arima_model import ARIMA
from matplotlib import pyplot
from pandas import datetime
from matplotlib import pyplot
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression


# In[444]:


lb= LabelEncoder()


# In[445]:


felony_dataset['Charge Group Description'] = lb.fit_transform(felony_dataset['Charge Group Description'])
gkk= felony_dataset.groupby('year')['Charge Group Description'].sum().reset_index().sort_values('year',ascending=False)
gkk


# In[446]:


gkk.plot(x = "year", y = "Charge Group Description")


# In[447]:


# model.score(gkk[['year']],gkk['Charge Group Description'])
from sklearn.ensemble import GradientBoostingRegressor
model = GradientBoostingRegressor(n_estimators=10,learning_rate=1)
model.fit(gkk[['year']],gkk['Charge Group Description'])


# In[448]:


model.score(gkk[['year']],gkk['Charge Group Description'])


# In[449]:


# The projected number of felony arrests in 2019
arr= np.array([2019])
y_pred= model.predict([arr])
y_pred


# In[450]:


# LinearRegression
lr= LinearRegression()
lr.fit(gkk[['year']],gkk['Charge Group Description'])


# In[451]:


lr.score(gkk[['year']],gkk['Charge Group Description'])


# In[452]:


lr.coef_


# In[453]:


lr.intercept_


# In[454]:


# The projected number of felony arrests in 2019

arr= np.array([2019])
y_pred= lr.predict([arr])
y_pred


# In[455]:


# Predicitions using Time Series (Learning Purpose)
gkks=gkk.copy()
gkks['year']=pd.to_datetime(gkks['year'])
gkks.set_index('year',inplace=True)


# In[456]:


X = gkks.values
X


# In[457]:


autocorrelation_plot(X)


# In[458]:


from statsmodels.tsa.stattools import acf,pacf
autor=acf(X,nlags=3)
par=pacf(X,nlags=3,method='ols')
pyplot.plot(autor,label='std')


# In[459]:


import statsmodels.api as sms
model = sms.tsa.statespace.SARIMAX(X,order=(1,0,0))
result = model.fit()
print(result.summary())


# In[460]:


from statsmodels.tsa.statespace.sarimax import SARIMAX
from random import random

model = SARIMAX(X, order=(1, 3, 2))
model_fit = model.fit(disp=False)
# make prediction
yhat = model_fit.predict(len(X), len(X)+1)
print(yhat)


# In[465]:


# Question 6: How many arrest incidents occurred within 2 km from the Bradbury
# Building in 2018? Use (34.050536, -118.247861) for the coordinates of the Bradbury Building . 
# For simplicity, please use the spherical Earth projected to a plane equation for calculating distances. 
# Use the radius of the Earth as 6371 km. Note, some arrest records are missing location data and the location is listed 
# as (0, 0). These records should not factor in your calculation.


# In[466]:


from math import sin,cos,sqrt,atan2,radians


# In[467]:


def calculate_distance(coord):
    R=6371.0
    lat1=radians(34.050536)
    lon1=radians(-118.247861)
    lat2=radians(coord[0])
    lon2=radians(coord[1])
    dlon=lon2-lon1
    dlat=lat2-lat1
    
    a= sin(dlat/2)**2+ cos(lat1)+cos(lat2)+sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(a-1))

    distance = R*c
    return distance


# In[468]:


calculate_distance


# In[469]:


Arrestes_in_2018["distance_Bradbury"]=Arrestes_in_2018[(Arrestes_in_2018['Location']!="(0,0)")&(pd.notna(df['Location']))]['Location'].apply(lambda x: calculate_distance([float(y) for y in x[1:-1].split(",")]))
Arrestes_in_2018["distance_Bradbury"]


# In[ ]:




